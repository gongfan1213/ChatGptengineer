
一个二分类任务，明明一个很简单的模型就能解决，就没必要非得用一个很复杂的模型。除非像ChatGPT这样的大语言模型接口已经普及到一定程度——任何人都能够非常流畅、自由地使用；而且，我们就是想要简单、低门槛、快捷地实现功能。

言归正传，使用Embedding的应用大多跟语义相关，下面介绍几个与此相关的经典任务和应用。

#### 2.3.1 简单问答：以问题找问题
QA是问答的意思，Q表示Question，A表示Answer，QA是NLP非常基础和常用的任务。简单来说，就是当用户提出一个问题时，我们能从已有的问题库中找到一个最相似的问题，并把它的答案返回给用户。这里有两个关键点：第一，事先需要有一个QA库；第二，当用户提问时，要能够在QA库中找到一个最相似的问题。

用ChatGPT或其他生成模型执行这类任务有点麻烦，尤其是当QA库非常庞大时，以及当提供给用户的答案是固定的、不允许自由发挥时。生成方式做起来事倍功半，而Embedding与生俱来地非常适合，因为这类任务的核心就是在一堆文本中找出与给定文本最相似的文本。简单总结一下，QA问题其实就是相似度计算问题。

我们使用的是Kaggle提供的Quora数据集all-kaggle-questions-on-quora-dataset，该数据集可以从Kaggle官网搜索下载。下载后是一个CSV文件，先把它读进来。
```python
import pandas as pd

df = pd.read_csv('dataset/Kaggle_related_questions_on_Quora - Questions.csv')
df.shape == (1166, 4)
```
该数据集包括1166行、4列。使用`df.head()`可以读取数据集的前5条，结果如表2-1所示。

### 表2-1 Quora数据集样例


|索引|问题|关注人数|是否被回答（1表示是，0表示否）|链接地址|
| ---- | ---- | ---- | ---- | ---- |
|0|How do I start participating in Kaggle competi...|1200|1|/How-do-I-start-participating-in-Kaggle-compet...|
|1|Is Kaggle dead?|181|1|/Is-Kaggle-dead|
|2|How should a beginner get started on Kaggle?|388|1|/How-should-a-beginner-get-started-on-Kaggle|
|3|What are some alternatives to Kaggle?|201|1|/What-are-some-alternatives-to-Kaggle|
|4|What Kaggle competitions should a beginner sta...|273|1|/What-Kaggle-competitions-should-a-beginner-st...|

数据集中的第一列是问题，第二列是关注人数，第三列表示是否被回答，最后一列是对应的链接地址。

在这里，我们把最后一列的链接地址当作答案来构造QA数据对，基本流程如下。

- 第一步：对每个问题计算Embedding。

- 第二步：存储Embedding，同时存储每个问题对应的答案。

- 第三步：从存储的地方检索最相似的问题。


第一步可以借助OpenAI的Embedding接口，但是后两步得看实际情况。如果问题比较少，比如只有几万个甚至几千个，则可以把计算好的Embedding直接存储成文件，每次服务启动时，直接加载到内存或缓存中就好了。在使用时，逐个计算输入的问题和存储的所有问题的相似度，然后给出最相似的那个问题的答案。演示代码如下。

```python
from openai.embeddings_utils import get_embedding, cosine_similarity
import openai
import numpy as np

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
```

首先依然是导入需要的工具包，并配置好OPENAI_API_KEY。然后遍历DataFrame，计算Embedding并存储，如下所示。

```python
vec_base = []
for v in df.itertuples():
    emb = get_embedding(v.Questions)
    im = {
        "question": v.Questions,
        "embedding": emb,
        "answer": v.Link
    }
    vec_base.append(im)
```

接下来直接使用就可以了。比如，给定输入“is kaggle alive?”，我们先获取它的Embedding，再逐个遍历vec_base，计算相似度并取相似度最高的一个或若干答案作为响应。

```python
query = "is kaggle alive?"
q_emb = get_embedding(query)

sims = [cosine_similarity(q_emb, v["embedding"]) for v in vec_base]
```
为了方便展示，我们假设有5条，如下所示。

```python
sims == [
    0.665769204766594,
    0.8711775410642538,
    0.7489853201153621,
    0.7384357684745508,
    0.7287129153982224
]
```

此时，第二条相似度最高，我们返回第二个文档（索引为1）即可。

```python
vec_base[1]["question"], vec_base[1]["answer"] == ('Is Kaggle dead?', '/Is-Kaggle-dead')
```

如果要返回多个答案，则返回前面若干相似度较高的文档即可。当然，在实际中，我们不建议使用循环，那样效率比较低。我们可以使用NumPy进行批量计算。

```python
arr = np.array([v["embedding"] for v in vec_base])
```

这里先将所有问题的Embedding构造成一个NumPy数组。

```python
q_arr = np.expand_dims(q_emb, 0)
q_arr.shape == (1, 12288)
```

对于给定输入的Embedding，也将它变成NumPy数组。注意，我们需要扩展一个维度，以便于后面的计算。

```python
from sklearn.metrics.pairwise import cosine_similarity

sims = cosine_similarity(arr, q_arr)
```

使用sklearn包里的cosine_similarity可以批量计算两个数组的相似度。这里的批量计算主要利用了NumPy的向量化计算，可以极大地提升效率，建议读者亲自尝试并体会这两种方案的效率差异。还是假设只有5条，结果如下所示。

```python
sims == array([
    [0.6657692 ],
    [0.87117754],
    [0.74898532],
    [0.73843577],
    [0.72871292]
])
```

不过，当问题非常多时，比如多到上百万甚至上亿，这种方式就不合适了：一方面，内存中可能放不下；另一方面，计算起来也慢。这时候，就必须借助一些专门用来做语义检索的工具了。比较常用的语义检索工具有下面三个。
- Meta的faiss：高效的相似性搜索和稠密向量聚类库。
- milvus-io网站的Milvus：可扩展的相似性搜索和面向人工智能应用的向量数据库。
- Redis：是的，Redis也支持向量搜索。


此处，我们以Redis为例，其他语义检索工具的用法与之类似。首先，我们需要一个Redis服务，建议使用Docker直接运行它。

```bash
$ docker run -p 6379:6379 -it redis/redis-stack:latest
```

执行以上命令后，Docker会自动把镜像拉到本地，默认是6379端口，将其映射出来。然后安装redis-py，也就是Redis的Python客户端，如下所示。

```bash
$ pip install redis
```
这样我们就可以用Python和Redis交互了。下面是一个最简单的例子。

```python
import redis

r = redis.Redis()
r.set("key", "value")
```

我们初始化了一个Redis实例，然后设置了一个键 - 值（key-value）对，其中键就是字符串key，值是字符串value。现在就可以通过键获取相应的值，如下所示。
```python
r.get("key") == b'value'
```

接下来的步骤和刚才将问题加载到内存中的步骤差不多，但是这里需要先建好索引，再生成Embedding并把它们存储到Redis中，最后加以使用（从索引中搜索）。由于我们使用了向量工具，具体步骤会略微不同。 


