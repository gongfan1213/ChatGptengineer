### 相似匹配——万物皆可Embedding

索引的概念和数据库中的索引有点类似，需要先定义一组Schema，以告诉Redis每个字段是什么，以及都有哪些属性。还是先导入需要的依赖。
```python
from redis.commands.search.query import Query
from redis.commands.search.field import TextField, VectorField
from redis.commands.search.indexDefinition import IndexDefinition
```
再定义字段和Schema。
```python
# 向量维度
VECTOR_DIM = 12288
# 索引名称
INDEX_NAME = "faq"
# 建好要存字段的索引，针对不同属性字段，使用不同的Field
question = TextField(name="question")
answer = TextField(name="answer")
embedding = VectorField(
    name="embedding",
    algorithm="HNSW",
    attributes={
        "TYPE": "FLOAT32",
        "DIM": VECTOR_DIM,
        "DISTANCE_METRIC": "COSINE"
    }
)
schema = (question, embedding, answer)
```
上面embedding字段里的HNSW表示层级可导航小世界（hierarchical navigable small worlds, HNSW）算法。这是一种用于高效相似性搜索的算法，主要思想是将高维空间中的数据点组织成一个多层级的图结构，使得相似的数据点在图上彼此靠近。搜索时，可以先通过粗略的层级找到一组候选数据点，再逐渐细化搜索，直至找到最近似的邻居（数据点）。

接下来尝试创建索引，如下所示。
```python
index = r.ft(INDEX_NAME)  # ft表示full text search
```
```python
try:
    info = index.info()
except:
    index.create_index(schema, definition=IndexDefinition(prefix=[INDEX_NAME + "-"]))
```
建好索引后，就可以往里面导入数据了。有时候，我们可能需要删除已有的文档，这可以使用下面的命令来实现。
```python
index.dropindex(delete_documents=True)
```
再往后就是把数据导入Redis，整体逻辑和之前类似，不同的是需要将Embedding的浮点数存为字节。
```python
for v in df.itertuples():
    emb = get_embedding(v.Questions)
    # 注意，Redis要存储字节或字符串
    emb = np.array(emb, dtype=np.float32).tobytes()
    im = {
        "question": v.Questions,
        "embedding": emb,
        "answer": v.Link
    }
    # 重点是hset操作
    r.hset(name=f"{INDEX_NAME}-{v.Index}", mapping=im)
```
然后就可以进行搜索查询了，构造查询输入稍微有一点麻烦，需要写一些查询语句。
```python
# 构造查询输入
query = "kaggle alive?"
embed_query = get_embedding(query)
params_dict = {"query_embedding": 
               np.array(embed_query).astype(dtype=np.float32).tobytes()}
```
获取给定输入的Embedding和之前一样，构造参数字典就是为了将其转为字节。接下来编写并构造查询，如下所示。
```python
k = 3
base_query = f"* => [KNN {k} @embedding $query_embedding AS score]"
return_fields = ["question", "answer", "score"]
query = (
    Query(base_query)
   .return_fields(*return_fields)
   .sort_by("score")
   .paging(0, k)
   .dialect(2)
)
```
查询语法为`{some filter query}=>[ KNN {num|$num} @vector_field $query_vec]`，其中包括以下两项。
- `{some filter query}`：字段过滤条件，可以使用多个条件。`*`表示任意。
- `[ KNN {num|$num} @vector_field $query_vec]`：K最近邻算法（K nearest neighbors, KNN）的主要思想是对未知数据点分别和已有的数据点算距离，挑距离最近的K个数据点。num表示K。vector_field是索引里的向量字段，这里是embedding。query_vec是参数字典中表示给定输入的Embedding的名称，这里是query_embedding。

AS score表示K最近邻算法计算结果的数据名称为score。注意，这里的score其实是距离，不是相似度。换句话说，score越小，相似度越大。

paging表示分页，参数为offset和num，默认值分别为0和10。

dialect表示查询语法的版本，不同版本之间会有细微差别。

此时，我们就可以通过search接口直接进行查询了，查询过程和结果如下。
```python
# 查询
res = index.search(query, params_dict)
for i, doc in enumerate(res.docs):
    # 注意相似度和分数正好相反
    similarity = 1 - float(doc.score)
    print(f"{doc.id}, {doc.question}, {doc.answer} (Similarity: {round(similarity, 3)})")
```
最终输出内容如下。
```
faq-1, Is Kaggle dead?, /Is-Kaggle-dead (Score: 0.831)
faq-2, How should a beginner get started on Kaggle?, /How-should-a-beginner-get-started-on-Kaggle (Score: 0.735)
faq-3, What are some alternatives to Kaggle?, /What-are-some-alternatives-to-Kaggle (Score: 0.73)
```
上面我们通过几种不同的方法向大家介绍了如何使用Embedding执行QA任务。简单回顾一下，要执行QA任务，首先得有一个QA库，这个QA库就是我们的仓库。每当一个新的问题到来时，就用这个新问题和我们仓库里的每一个问题做匹配，然后找到最相似的那个问题，接下来就把该问题的答案当作新问题的答案交给用户。

QA任务的核心就是找到与新问题最相似的那个问题，这涉及两个知识点：如何表示一个问题，以及如何找到相似的问题。对于第一个知识点，我们用接口提供的Embedding表示，我们可以把它当作一个黑盒子，输入任意长度的文本，输出一个向量。查找相似问题则需要用到相似度算法，语义相似度一般用余弦距离来衡量。

当然，实际中可能会更加复杂一些，比如我们可能除了使用语义匹配，还会使用字词匹配（这是一种经典的做法）。而且，我们一般都会找到若干最为相似的问题，然后对这些问题进行排序，选出最相似的那个问题。对此，2.2.2节已经举过例子了，我们现在完全可以通过ChatGPT这样的大语言模型接口来解决，让它帮你找出最相似的那个问题。

#### 2.3.2 聚类任务：物以类聚也以群分
聚类的意思是把彼此相近的样本聚集在一起，本质也是使用一种表示和相似度度量来处理文本。假设我们有大量的未分类文本，如果能事先知道有几个类别，就可以用聚类的方法先将样本大致分一下。

本小节使用Kaggle的DBPedia数据集DBPedia Classes，该数据集可以从Kaggle官网搜索下载。该数据集会对一段文本给出三个不同层次级别的分类标签，这里以第一层的类别为例。和QA任务一样，依然先读取并查看数据。
```python
import pandas as pd

df = pd.read_csv("./dataset/DBPEDIA_val.csv")
df.shape == (36003, 4)
df.head()
```
使用`df.head()`可以读取数据集的前5条，如表2-2所示，数据集中的第一列是文本，第二、三、四列分别是三个层级的标签。

### 表2-2 DBPedia数据集样例


|索引|文本|l1|l2|l3|
| ---- | ---- | ---- | ---- | ---- |
|0|Li Curt is a station on the Bernina Railway li...|Place|Station|RailwayStation|
|1|Grafton State Hospital was a psychiatric hospi...|Place|Building|Hospital|
|2|The Democratic Patriotic Alliance of Kurdistan...|Agent|Organisation|PoliticalParty|
|3|Ira Rakatansky (October 3, 1919 – March 4, 201...|Agent|Person|Architect|
|4|Universitatea Resita is a women handball club ...|Agent|SportsTeam|HandballTeam|

接下来查看类别数量，使用`value_counts`可以统计出每个值出现的频次，这里我们只看第一层的标签。
```python
df.l1.value_counts()
```
结果如下所示，可以看到，Agent数量最大，Device数量最小。
```
Agent         18647
Place          6855
Species        3210
Work           3141
Event          2854
SportsSeason    879
UnitOfWork      263
TopicalConcept  117
Device           37
Name: l1, dtype: int64
```
由于整个数据集比较大，展示起来不太方便，我们随机采样200条。
```python
sdf = df.sample(200)
sdf.l1.value_counts()
```
随机采样使用的是`sample`接口，所采样数据的分布和采样源是接近的。
```
Agent     102
Place      31
Work       22
Species    19
Event      12
SportsSeason 10
UnitOfWork  3
TopicalConcept 1
Name: l1, dtype: int64
```
为了便于观察，我们只保留3个数量差不多的类别——Place、Work和Species（当类别太多时，样本点会混在一块难以观察，读者不妨自己尝试一下）。
```python
cdf = sdf[
    (sdf.l1 == "Place") | (sdf.l1 == "Work") | (sdf.l1 == "Species")
]
cdf.shape == (72, 6)
```
我们过滤了其他标签，只保留了选定的3个类别，最终数据量是72条，相信观察起来会非常直观。

由于需要把文本表示成向量，因此有必要先把工具准备好。
```python
from openai.embeddings_utils import get_embedding, cosine_similarity
import openai
import numpy as np

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
```
前面提到过，这个`get_embedding`接口可以支持多种模型（engine参数），默认是`text-similarity-davinci-001`，这里使用了`text-embedding-ada-002`，后者稍微快一些（维度相比前者少很多）。
```python
cdf["embedding"] = cdf.text.apply(lambda x: get_embedding(x, engine="text-embedding-ada-002"))
```
接下来使用主成分分析（principal component analysis, PCA）算法进行特征降维，将原来的向量从1536维降至3维，以便于显示（超过3维就不好绘制了）。
```python
from sklearn.decomposition import PCA

arr = np.array(cdf.embedding.to_list())
pca = PCA(n_components=3)
vis_dims = pca.fit_transform(arr)
cdf["embed_vis"] = vis_dims.tolist()
arr.shape == (72, 1536), vis_dims.shape == (72, 3)
```
可以看到，得到的`vis_dims`只有3维，这3个维度就是最重要的3个特征，我们可以说，这3个特征能够“大致上”代表所有的1536个特征。然后就是将所有数据可视化，也就是把3种类型的点（每个点3个维度）在3维空间中绘制出来。
```python
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

fig, ax = plt.subplots(subplot_kw={"projection": "3d"}, figsize=(8, 8))
cmap = plt.get_cmap("tab20")
```
```python
categories = sorted(cdf.l1.unique())

# 分别绘制每个类别
for i, cat in enumerate(categories):
    sub_matrix = np.array(cdf[cdf.l1 == cat]["embed_vis"].to_list())
    x = sub_matrix[:, 0]
    y = sub_matrix[:, 1]
    z = sub_matrix[:, 2]
    colors = [cmap(i/len(categories))] * len(sub_matrix)
    ax.scatter(x, y, z, c=colors, label=cat)

ax.legend(bbox_to_anchor=(1.2, 1))
plt.show()
```
绘制结果如图2-1所示。


![image](https://github.com/user-attachments/assets/662ea14a-90de-4f2b-bbd8-bc966e5a4313)


### 图2-1 聚类示意图
（此处有一张三维散点图，展示不同类别数据点分布，图中用不同颜色区分Place、Species、Work类别 ）

可以比如果事先过KMeans间相似度
- 随
- 将
- 计
- 重

示例
```python
from sklearn.cluster import KMeans

kmeans = 
```
然后聚类方法精度但有一些络分析等

#### 2.3.3 推
我们或选购做一个类闻等。我
- 盲
- 计
- 这 的 
