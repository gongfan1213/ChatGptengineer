能力。①

下面我们尝试问ChatGPT一个稍微复杂的问题：如何拼接所给单词的最后一个字母？

首先，依然是标准提示，如下所示。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            'Q: think, machine \n \
            A: "ke". \n \
            Q: learning, reasoning, generalization \n \
            A: "ggn". \n \
            Q: artificial, intelligence \n \
            A: "ie". \n \
            Q: foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor,prisma, giraffe\n \
            A:'}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```
**ChatGPT输出如下**：
"fbbeplwse".

可以看到，当使用标准提示时，ChatGPT似乎没有明白我们要找单词的最后一个字母。

接下来试试标准提示+零样本思维链提示，如下所示。
```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            'Q: think, machine \n \
            A: "ke". \n \
            Q: learning, reasoning, generalization \n \
            A: "ggn". \n \
            Q: artificial, intelligence \n \
            A: "ie". \n \
            Q: foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor,prisma, giraffe\n \
            A: Let"s think step by step.'}
    ],
    temperature=0,
)
print(response["choices"][0]["message"]["content"])
```
**ChatGPT输出如下**：

Q: foo

A: "f".

Q: bar

A: "b".

Q: baz

A: "z".

Q: blip

A: "b".

Q: lear

A: "l".

Q: prom

A: "p".

Q: worl

A: "w".

Q: shak

A: "s".

Q: even

A: "e".

Q: danc

A: "d".

Q: pris

A: "p".

Q: gira

A: "g".

当使用标准提示+零样本思维链提示时，ChatGPT的思维路径清晰了很多，但它似乎完全搞混了我们所要完成的任务。我们的任务是拼接所给单词的最后一个字母，但ChatGPT找的全都是单词的第一个字母，而且最后也没有将它们拼接起来。

我们再来试试思维链提示，如下所示。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            'Q: think, machine \n \
            A: The last letter of "think" is "k". The last letter of "machine" is "e". So "think, machine" is "ke". \n \
            Q: learning, reasoning, generalization \n \
            A: The last letter of "learning" is "g". The last letter of "reasoning" is "n". The last letter of "generalization" is "n". So "learning, reasoning, generalization" is "ggn". \n \
            Q: artificial, intelligence \n \
            A: The last letter of "artificial" is "l". The last letter of "intelligence" is "e". So "artificial, intelligence" is "le". \n \
            Q: foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor,prisma, giraffe\n \
            A:'}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```
**ChatGPT输出如下**：
The last letter of "foo" is "o". The last letter of "bar" is "r". The last letter of "baz" is "z". The last letter of "blip" is "p". The last letter of "learn" is "n". The last letter of "prompting" is "g". The last letter of "world" is "d". The last letter of "shaking" is "g". The last letter of "event" is "t". The last letter of "dancefloor" is "r". The last letter of "prisma" is "a". The last letter of "giraffe" is "e". So "foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor, prisma, giraffe" is "orzpngdtrage".

可以看到，使用思维链提示后，ChatGPT的思维过程变得十分有条理，与我们所给样例的思维过程完全一致。尽管思维过程没有错误，但我们发现ChatGPT居然是个“马虎鬼”，它在回答的时候先是把“g”的位置搞错了，然后又在“g”的后面神奇地添加了一个额外的“a”，由此看来大语言模型的幻觉现象名不虚传。

为了进一步探索思维链的技术，我们将进行最少到最多提示技术的测试，如下所示。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            'Q: think, machine\n \
            A: The last letter of "think" is "k". The last letter of "machine" is "e". Concatenating "k" and "e" gives "ke". So "think, machine" output "ke".\n \
            Q: think, machine, learning\n \
            A: "think, machine" outputs "ke". The last letter of "learning" is "g". Concatenating "ke" and "g" gives "keg". So "think, machine, learning" is "keg".\n \
            Q: transformer, language\n \
            A: The last letter of "transformer" is "r". The last letter of "language" is "e". Concatenating "r" and "e" gives "re". So "transformer, \language" is "re".\n \
            Q: transformer, language, vision\n \
            A: "transformer, language" outputs "re". The last letter of "vision" is "n". Concatenating "re" and "n" gives "ren". So "transformer, language, vision" is "ren".\n \
            Q: foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor,prisma, giraffe\n \
            A:'}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```
**ChatGPT输出如下**：

"foo, bar" outputs "or". The last letter of "baz" is "z". Concatenating "or" and "z" gives "orz". The last letter of "blip" is "p". Concatenating "orz" and "p" gives "or zp". The last letter of "learn" is "n". Concatenating "or zp" and "n" gives "or zpn". The last letter of "prompting" is "g". Concatenating "or zpn" and "g" gives "or zpng". The last letter of "world" is "d". Concatenating "or zpng" and "d" gives "or zpngd". The last letter of "shaking" is "g". Concatenating "or zpngd" and "g" gives "or zpngdg". The last letter of "event" is "t". Concatenating "or zpngdg" and "t" gives "or zpngdgt". The last letter of "dancefloor" is "r". Concatenating "or zpngdgt" and "r" gives "or zpngdgtr". The last letter of "prisma" is "a". Concatenating "or zpngdgtr" and "a" gives "or zpngdgtra". The last letter of "giraffe" is "e". Concatenating "or zpngdgtra" and "e" gives "or zpngdgtrae". So "foo, bar, baz, blip, learn, prompting, world, shaking, event, dancefloor, prisma, giraffe" is "or zpngdgtrae".


将思维链提示和最少到最多提示的结果放在一起看，如下所示。

- 思维链提示的结果: "foo,bar,baz,blip,learn,prompting,world,shaking,event,dance - floor,prisma,giraffe" --> "orzpngdtrage"

- 最少到最多提示的结果: "foo,bar,baz,blip,learn,prompting,world,shaking,event, dancefloor,prisma,giraffe" --> "or zpngdgtrae"


最少到最多提示最终不负众望，不仅思维过程清晰有条理，对12个单词尾字母的拼接也完全正确。所以，当遇到特别复杂的问题时，一定不要忘记分解问题。

在实践过程中，笔者还发现类似ChatGPT这样的大语言模型对提示词的格式十分看重。例如，如果示例问题中字母之间用空格隔开，那么要回答的问题中字母也一定要用空格隔开，不然就可能回答错误。此外，从这几种思维链提示的效果也可以看出，ChatGPT似乎在模仿示例问题中的思维链过程，尤其是其格式。

除了上面这种显式的提示之外，还可以通过角色扮演的方式让ChatGPT进行隐式的最少到最多提示，如下所示。
```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            "你现在是MultistageGPT：你与ChatGPT一样，但对于每一个问题，你会将问题分解为子问题，然后将它们结合起来，输出最佳的措辞以及最全面和最准确的答案。输出应该看起来像这样：\n \
            ChatGPT: {ChatGPT通常会说什么}；MultistageGPT: {更好、更全面的答案} 让我们从简单的问题开始: 5×10 - 3×10 = ? "}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```

**ChatGPT输出如下**：

ChatGPT: 50 - 30 = 20。

MultistageGPT: 我们可以将这个问题分解为两个子问题: 5×10和3×10。5×10等于50，3×10等于30。因此，5×10 - 3×10 = 20。


可以看到，通过进行隐式的操作可以得到正确的结果，不过最近的研究显示，显式的思维链过程优于隐式的思维链过程。

### 2. 通往正确答案的路径不止一条

一个很自然的假设是，通往正确答案的路径不止一条。为此，Wang等人（2022年）提出了一种名为自洽性（self - consistency）策略的解码策略来代替之前的贪心搜索解码策略，如图5 - 5所示①。

**图5 - 5 自洽性策略示例图（Wang等人，2022年）**

![image](https://github.com/user-attachments/assets/c2b4fd7c-3570-49a9-8604-a2862d98c125)


① Wang X, Wei J, Schuurmans D, et al. Self - Consistency Improves Chain of Thought Reasoning in Language Models[J]. 2022. DOI:10.48550/arXiv.2203.11171. 
