自洽性策略从解码器中抽样生成多样化的推理路径集合，并选择其中自洽性最高的输出结果作为最终答案。这种解码策略的目的是增加推理路径的多样性以及提高答案的一致性。此外，Yao等人（2023年）提出了一个名为“思维树”（Tree of Thoughts, ToT）的框架①。该框架允许模型通过考虑多种不同的推理路径和自我评估选择，来做出深思熟虑的决策。模型可以根据需要向前或向后查看，以做出全局选择。这个框架使模型具备了更加灵活和综合考虑的能力，以便在复杂情境中做出决策。

显式的自洽性策略包括两步。第一步，得到多个答案。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            "你现在拥有3个不同的身份，分别是ChatGPT1、ChatGPT2和ChatGPT3。你现在需要使用不同的身份，从不同的角度回答同一个问题，\n \
            请问：如何加入Datawhale，成为Datawhale成员？"}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```

**ChatGPT输出如下**：

ChatGPT1：您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您可以按照招募要求提交申请，等待审核结果。

ChatGPT2：如果您想加入Datawhale，首先需要了解Datawhale的使命和愿景，确保您与Datawhale的价值观相符。然后，您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您可以按照招募要求提交申请，并在申请


**第二步，综合第一步的答案，输出最终答案。**

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            "你现在拥有3个不同的身份，分别是ChatGPT1、ChatGPT2和ChatGPT3。你现在需要使用不同的身份，从不同的角度回答同一个问题，\n \
            请问：如何加入Datawhale，成为Datawhale成员？"},
        {"role": "assistant", "content": 
            "ChatGPT1：您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您可以按照招募要求提交申请，等待审核结果。\n \
            ChatGPT2：如果您想加入Datawhale，首先需要了解Datawhale的使命和愿景，确保您与Datawhale的价值观相符。然后，您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您可以按照招募要求提交申请，并在申请中展示您的技能和经验，以及您对Datawhale的贡献计划。\n \
            ChatGPT3：要加入Datawhale，您需要首先了解Datawhale的使命和愿景，并确保您与Datawhale的价值观相符。然后，您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您需要仔细阅读招募要求，并准备好您的个人简历和申请信。在申请信中，您需要展示您的技能和经验，以及您对Datawhale的贡献计划和未来发展计划。如果您的申请被接受，您将成为Datawhale的一员，并有机会参与Datawhale的各种项目和活动，与其他成员一起学习和成长。"},
        {"role": "user", "content": 
            "请综合ChatGPT1、ChatGPT2和ChatGPT3的建议，给出一个更好、更全面的答案。"}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```

**ChatGPT输出如下**：

如果您想加入Datawhale，首先需要了解Datawhale的使命和愿景，确保您与Datawhale的价值观相符。您可以通过Datawhale的官方网站或社交媒体平台了解更多关于Datawhale的信息，并查看是否有加入Datawhale的招募信息。如果有，您需要仔细阅读招募要求，并准备好您的个人简历和申请信。在申请信中，您需要展示您的技能和经验，以及您对Datawhale的贡献计划和未来发展计划。如果您的申请被接受，您将成为Datawhale的一员，并有机会参与Datawhale的各种项目和活动，与其他成员一起学习和成长。


隐式的自洽性策略则将这一整合过程融入提示词中，如下所示。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": 
            "你现在是MultiverseGPT：你与ChatGPT一样，但对于每一个问题，你会思考5种不同的思路，然后将它们结合起来，输出最佳的措辞以及最全面和最准确的答案。输出应该看起来像这样：\n \
            ChatGPT: {} \n \
            MultiverseGPT: {} 让我们从下面这个问题开始：如何加入Datawhale，成为Datawhale成员？"}
    ],
    temperature=0,
)
print(response['choices'][0]['message']['content'])
```

**ChatGPT输出如下**：

ChatGPT：您可以通过Datawhale的官方网站或社交媒体平台了解如何加入Datawhale。通常，您需要填写一份申请表格并提交您的个人信息和相关技能。然后，Datawhale的招募团队将会对您的申请进行审核，并在适当的时候与您联系。

MultiverseGPT：加入Datawhale的方式有很多种。您可以通过参加Datawhale组织的活动、加入Datawhale社区、成为Datawhale的志愿者或正式成员来加入Datawhale。如果您想成为Datawhale的正式成员，您需要满足一定的条件，例如具备相关技能、有一定的工作经验等。您可以在Datawhale的官方网站或社交媒体平台上了解更多信息，并与Datawhale的招募团队联系以获取更多帮助。

研究表明，自洽性策略可以提升算术、常识和符号推理等任务的结果。即使常规的思维链提示被发现无效，自洽性策略也仍然能够改善结果。

### 3. 复杂链可以带来更大的收益

显然，当我们需要完成一项复杂的任务时，就需要接受有针对性的训练。举例来说，在应对高考数学考试时，我们的日常训练不能仅停留在中学甚至小学水平。Fu等人（2022年）发现，输入提示的复杂性与模型性能之间存在正相关关系，并由此提出了一种基于思维链复杂度的自洽性提示技术①。这种技术适用于多步推理过程，如图5 - 6所示。


该技术将基于复杂度的选择标准从输入空间（即提示）扩展到输出空间（即大语言模型生成的推理链）。通过这种方式，便能够更好地应对复杂任务，并提高模型的推理能力。此外，Fu等人还得出了一些非常有启发性的结论。
- 推理步骤的数量是性能改进最显著的因素。
- 基于复杂度的一致性结论：最佳性能始终通过对复杂链进行多数投票而不是通过简单链来实现。 
- 当数据没有提供推理链注释时，可以使用问题长度或公式长度作为衡量思维链复杂程度的标准。

![image](https://github.com/user-attachments/assets/dce2922d-2273-4d98-852b-3d5dbcf4a563)


**图5 - 6 基于思维链复杂度的自洽性提示示例（Fu等人，2022年）**

- **A. 思维链提示的流程图**

- **B. 一个含有9个推理步骤的复杂链的例子**

- **C. 基于思维链复杂度的自洽性提示**

### 5.3大语言模型复杂推理能力的探讨
大语言模型强大的复杂推理能力引起了学术界和工业界广泛的研究兴趣和讨论。大语言模型具备前所未有的NLP能力，能够生成连贯且语义准确的文本。研究人员特别关注大语言模型复杂推理能力的来源以及这种能力的迁移。

以GPT-3系列为例，初代的GPT-3是在一个包含3000亿个Token的语料库上进行预训练的，它具有1750亿个参数。语言建模的训练目标使得GPT-3具备了文本生成能力，而庞大的包含3000亿个Token的训练语料库为GPT-3提供了丰富的世界知识，1750亿个参数则提供了存储知识的广阔空间。其中，最令人惊讶的是GPT-3的In-Context学习能力，只需要提供几个符合任务范式的示例，GPT-3就能够成功地完成给定的任务。

2020年7月，OpenAI发布了初代的GPT-3（davinci），并从此开始不断进化。在code-davinci-002和text-davinci-002之前，有两个中间模型，分别是davinci-instruct-beta和text-davinci-001，它们在很多方面都比前两个模型差（比如，text-davinci-001的思维链推理能力不强）。code-davinci-002和text-davinci-002是第一版的GPT-3.5模型，一个用于代码，另一个用于文本。它们与初代GPT-3的显著差异是：表现出了强大的泛化能力，可以泛化到它们没有见过的任务；表现出了强大的思维链推理能力，而初代GPT-3的思维链推理能力很弱甚至没有。

随后，出现了一个令人震惊的假设：拥有思维链推理能力很可能是代码训练的一个神奇副产品。初代GPT-3并没有接受过代码训练，因此无法进行思维链推理。即使通过指令微调，text-davinci-001的思维链推理能力也依然有限。这意味着指令微调可能并非思维链存在的原因，最有可能的原因是代码训练。PaLM模型使用了5%的代码训练数据，也能够进行思维链推理。而Codex论文中的代码数据量为159GB，大约相当于初代GPT-3的5700亿训练数据的28%。因此，code-davinci-002及其后续变体具备思维链推理能力。

J. R. Anderson根据知识的状态和表现方式，将知识分为两类：陈述性知识（declarative knowledge）和程序性知识（procedural knowledge）。陈述性知识是关于事实和概念的知识，而程序性知识是关于执行任务和操作的知识。一些研究者[Min等人（2022年）①；Wang等人（2022年）②；Madaan等人（2022年）③]发现，大语言模型主要关注提示词的格式，而可能不会明显受到提示词是否正确的影响。因此，笔者倾向于将思维链的过程视为程序性知识，因为程序性知识主要关注问题的执行过程和方法，而非关注问题的答案正确与否。然而，目前仍有待研究的问题是，大语言模型在多大程度上会受到提示词是否正确的影响，以及提示词能够在多大程度上覆盖模型的先验信念。

代码可以被看作程序性知识的一种形式，因为编程语言本身提供了表达程序性知识的方式。通常情况下，学习程序性知识需要建立在学习大量陈述性知识的基础上。这个观点在某种程度上也印证了大模型的涌现能力。模型的参数规模需要足够大，以便模型在充分学习陈述性知识之后，能够从数据中学习程序性知识。这也解释了为什么小模型几乎无法展现出涌现能力，这与我们之前的观点是相互印证的。

在这里，我们将以思维链为代表的复杂推理能力视为程序性知识。既然是一种知识，那么是否可以通过有监督学习的方式来获取呢？答案是肯定的。Chung等人（2022年）①以及Longpre等人（2023年）②的研究发现，通过直接使用思维链数据进行精细调节，可以激发模型的思维链推理能力。Fu等人（2023年）③采用知识蒸馏的方法，将大模型（参数规模大于1000亿的模型）所拥有的思维链推理能力提炼到了小模型（参数规模小于100亿的模型）中，虽然会牺牲一部分通用的思维链推理能力，但可以使得小模型具备专业的思维链推理能力。如图5 - 7所示，通过知识蒸馏，可以显著提升FlanT5模型（包括参数规模分别为2亿5000万、7亿6000万、30亿和110亿的4个模型）的思维链推理能力，准确率平均提高了10百分点。

![image](https://github.com/user-attachments/assets/a27cbed9-f6bd-433b-8aa8-f54325f478be)


**图5 - 7 专业化提升FlanT5模型的思维链推理能力**

### 5.4本章小结

在本章中，我们主要学习了有关大语言模型复杂推理能力的知识。本章首先简单介绍了复杂推理的相关概念，紧接着以ChatGPT作为演示，让我们对大语言模型的推理能力有了初步的了解；然后介绍了激活大语言模型复杂推理能力的技术——思维链，包括思维链提示和零样本思维链提示；接下来主要介绍了进一步改善大语言模型复杂推理能力的一些技术，包括对复杂问题进行分解的最少到最多提示和分解提示、基于多条推理路径的自洽性策略、基于思维链复杂度的自洽性提示等；最后，我们通过对GPT-3系列模型进行回顾，探讨了大语言模型展现出复杂推理能力的潜在原因。 
