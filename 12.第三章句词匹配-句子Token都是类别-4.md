
限于篇幅，这里省略部分输出。对于找到的5个相关文档，由于上下文有长度限制（500），这里只使用前两个文档。 

构造好提示词后，最后一步就是基于给定文档回答问题。

```python
def complete(prompt: str) -> str:
    response = openai.Completion.create(
        prompt=prompt,
        temperature=0,
        max_tokens=300,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        model="text-davinci-003"
    )
    ans = response["choices"][0]["text"].strip("\n")
    return ans
ans = complete(prompt)
ans == "Gianmarco Tamberi and Mutaz Essa Barshim emerged as joint winners of the event following a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal."
```

我们再来试试ChatCompletion接口。

```python
def ask(content: str) -> str:
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": content}]
    )
    ans = response.get("choices")[0].get("message").get("content")
    return ans
ans = ask(prompt)
ans == "Gianmarco Tamberi and Mutaz Essa Barshim shared the gold medal in the men's high jump event at the 2020 Summer Olympics."
```

可以看到，接口ChatCompletion和Completion都准确地回答了问题。下面我们再多看几个例子。

```python
query = "In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win?"
prompt = construct_prompt(query)
answer = complete(prompt)
print(f"\nQ: {query}\nA: {answer}")
"""
Selected 2 document sections:
2020 Summer Olympics medal tableSummary
List of 2020 Summer Olympics medal winnersSummary
Q: In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win?
A: The United States won the most medals overall, with 113, and the most gold medals, with 39.
"""
answer = ask(prompt)
print(f"\nQ: {query}\nA: {answer}")
"""
Q: In the 2020 Summer Olympics, how many gold medals did the country which won the most medals win?
A: The country that won the most medals at the 2020 Summer Olympics was the United States, with 113 medals, including 39 gold medals.
"""
```

上面的问题是：“在2020年夏季奥运会上，获得奖牌最多的国家获得了多少枚金牌？”我们分别用接口ChatCompletion和Completion给出了答案，结果差不多，但前者更具体一些。

```python
query = "What is the tallest mountain in the world?"
prompt = construct_prompt(query)
answer = complete(prompt)
print(f"\nQ: {query}\nA: {answer}")
"""
Selected 3 document sections:
Sport climbing at the 2020 Summer Olympics - Men's combinedRoute-setting
Ski mountaineering at the 2020 Winter Youth Olympics - Boys' individualSummary
Ski mountaineering at the 2020 Winter Youth Olympics - Girls' individualSummary
Q: What is the tallest mountain in the world?
A: I don't know.
"""
answer = ask(prompt)
print(f"\nQ: {query}\nA: {answer}")
"""
Q: What is the tallest mountain in the world?
A: I don't know.
```

上面的问题是：“世界上最高的山是什么山？”这个问题依然可以召回3个文档，但其中并不包含答案。接口ChatCompletion和Completion都可以很好地按照我们预设的要求给出回复。 

文档问答是一个非常适合大语言模型的应用，它充分利用了大语言模型强大的理解能力。同时，由于每个问题都有相关的文档作为基础，从而最大限度地降低了大语言模型胡乱发挥的可能性。而且，从笔者的实验情况来看，这样的用法即使在零样本、不微调的情况下效果也不错。读者如果恰好有类似场景，不妨试试本方案。

### 3.3.2 模型微调：满足个性化需要 

前面已经介绍了句词分类和实体抽取方法的用法。本小节将介绍如何在自己的数据上进行微调，我们以主题分类任务为例。主题分类，简单来说就是根据给定文本，判断其属于哪一类主题。 

本小节使用今日头条中文新闻分类数据集，该数据集共15个类别，分别为科技、金融、娱乐、世界、汽车、运动、文化、军事、旅游、游戏、教育、农业、房产、社会、股票。

```python
import pnlp
lines = pnlp.read_file_to_list_dict("./dataset/tnews.json")
len(lines) == 10000
```

先读取数据集，其中一条样例数据如下所示。

```python
lines[59] == {
    "label": "101",
    "label_desc": "news_culture",
    "sentence": "上联：银笛吹开云天月，下联怎么对？",
    "keywords": ""
}
```

其中，label和label_desc分别是标签ID和标签描述，sentence是句子文本，keywords是关键词（它有可能为空）。我们先看统计的标签分布情况。

```python
from collections import Counter
ct = Counter([v["label_desc"] for v in lines])
ct.most_common() == [
    ('news_tech', 1089),
    ('news_finance', 956),
    ('news_entertainment', 910),
    ('news_world', 905),
    ('news_car', 791),
    ('news_sports', 767),
    ('news_culture', 736),
    ('news_military', 716),
    ('news_travel', 693),
    ('news_game', 659),
    ('news_edu', 646),
    ('news_agriculture', 494),
    ('news_house', 378),
    ('news_story', 215),
    ('news_stock', 45)
]
```

根据统计情况，我们发现stock这个类别的数据有点少。在真实场景中，各个标签在大部分情况下是不均匀的。如果标签很少的类型是我们所要关注的，那就尽量再增加一些数据；否则，可以不做额外处理。 

用上面介绍过的两个接口来完成任务。先构建提示词，如下所示。

```python
def get_prompt(text: str) -> str:
    prompt = f"""对给定文本进行分类，类别包括：科技、金融、娱乐、世界、汽车、运动、文化、军事、旅游、游戏、教育、农业、房产、社会、股票。
给定文本：
{text}
类别：
"""
    return prompt
prompt = get_prompt(lines[0]["sentence"])
print(prompt)
"""
对给定文本进行分类，类别包括：科技、金融、娱乐、世界、汽车、运动、文化、军事、旅游、游戏、教育、农业、房产、社会、股票。
给定文本：
上联：银笛吹开云天月，下联怎么对？
类别：
"""
```

这个提示词把sentence当作给定文本，然后要求模型输出对应的类别。注意，这些类别应该提供给模型。然后就是通过调用接口来完成任务了。

```python
import openai
import os
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
def complete(prompt: str) -> str:
    response = openai.Completion.create(
        prompt=prompt,
        temperature=0,
        max_tokens=10,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        model="text-davinci-003"
    )
    ans = response["choices"][0]["text"].strip("\n")
    return ans
def ask(content: str) -> str:
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": content}],
        temperature=0,
        max_tokens=10,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0
    )
    ans = response.get("choices")[0].get("message").get("content")
    return ans
ans = complete(prompt)
ans == "文化"
ans = ask(prompt)
ans == "文化"
```

可以看到，这两个接口很好地完成了我们所给的任务。我们再看一个识别不太理想的例子，数据如下所示。

```python
lines[2] == {
    "label": "104",
    "label_desc": "news_finance",
    "sentence": "出栏一只羊亏损300元，究竟谁能笑到最后！",
    "keywords": "商品羊，养羊，羊价，饲羊，饲料"
}
prompt = get_prompt(lines[2]["sentence"])
complete(prompt) == "社会"
ask(prompt) == "农业"
```

分析这句话，我们感觉“农业”这个类别可能看起来更合适一些。不过，很遗憾，数据给出的标签是“金融”。这种情况在实际场景中也比较常见，一般可以用下面的手段来解决。

- **少样本**：可以每次随机地从训练数据集（简称训练集）中抽取几个样本（包括句子和标签）作为提示词的一部分。 

- **微调**：把我们自己的数据集按指定格式准备好，提交给微调接口，让它帮我们微调一个已经在我们所给的数据集上学习过的模型。 

少样本方案最关键的是如何找到“样本”，换句话说，我们拿什么样例给模型当作参考样本。对于类别标签比较多的情况（在实际工作场景中，成百上千种标签是很常见的），即使每个标签一个例子，上下文长度也比较难以接受。这时候，少样本方案就有点不太方便了。当然，如果我们非要用也不是不行，最常用的策略如下：首先召回几个相似句，然后把相似句的内容和标签作为少样本的例子，让接口来预测给定句子的类别。不过这样做的话，就与直接使用QA方法差不多了。 

此时，更好的方案就是在我们的数据集中微调模型，简单来说，就是让模型“熟悉”我们独特的数据，进而使其具备在类似数据上正确识别出相应标签的能力。 

接下来就让我们看看具体怎么做，一般包括三个主要步骤。

- **第一步**：准备数据。按接口要求的格式把数据准备好，这里的数据就是我们自己的数据集，其中至少包含一段文本和一个类别。 

- **第二步**：微调。使用微调接口将处理好的数据传递过去，由服务器自动完成微调，微调完成后，可以得到一个新的模型ID。注意，这个模型ID只属于你自己，不要将它公开给其他人。 

- **第三步**：使用新模型进行推理。这很简单，把原来接口里的model参数的内容换成刚刚得到的模型ID即可。 


注意，本书只介绍如何通过接口进行微调。下面我们就来微调这个主题分类模型，为了快速验证结果，我们只取后500条数据作为训练集。

```python
import pandas as pd
train_lines = lines[-500:]
train = pd.DataFrame(train_lines)
train.shape == (500, 4)
train.head(3)  # 只看前3条
```

主题分类微调数据集样例如表3-2所示，各列的含义之前已经解释过了，此处不赘述。需要说明的是，关键词有点类似于标签，它们并不一定会出现在原文中。

| 索引 | 标签 | 标签描述 | 句子 | 关键词 |

| ---- | ---- | ---- | ---- | ---- |
| 0 | 103 | news_sports | 为什么斯凯奇与阿迪达斯脚感很相似，价格却差了近一倍？ | 达斯勒，阿迪达斯，FOAM，BOOST，斯凯奇 |
| 1 | 100 | news_story | 女儿日渐消瘦，父母发现有怪物 | 大将军，怪物 |
| 2 | 104 | news_finance | 另类逼空确认反弹，剑指3200点以上 | 股票，另类逼空，金融，创业板，快速放大 |


统计一下各个类别的频次情况，如下所示。

```python
train.label_desc.value_counts()
"""
news_finance    48
news_tech       47
news_game       46
news_entertainment  46
news_travel     44
news_sports     42
news_military   40
news_world      38
news_car        36
news_culture    35
news_edu        27
news_agriculture    20
news_house      19
news_story      12
Name: label_desc, dtype: int64
"""
```

需要说明的是，实际运行时，由于股票数据量太小，我们把这个类别去掉了，但这不影响整个流程。 

首先是第一步：准备数据。要保证数据有两列，分别是prompt和completion。当然，不同服务商提供的接口可能不完全一样，这里以OpenAI的接口为例。

```python
df_train = train[["sentence", "label_desc"]]
df_train.columns = ["prompt", "completion"]
df_train.head()
```

构造好的主题分类微调训练数据样例如表3-3所示。

| 索引 | prompt | completion |
| ---- | ---- | ---- |
| 0 | 为什么斯凯奇与阿迪达斯脚感很相似，价格却差了近一倍？ | news_sports |
| 1 | 女儿日渐消瘦，父母发现有怪物 | news_story |
| 2 | 另类逼空确认反弹，剑指3200点以上 | news_finance |
| 3 | 老公在聚会上让我向他的上司敬酒，现在老公哭了，我笑了 | news_story |
| 4 | 女孩上初中之后成绩下降，如何才能提升成绩？ | news_edu |

将数据保存到本地，并使用OpenAI提供的命令行工具进行格式转换，转为要求的格式。 
