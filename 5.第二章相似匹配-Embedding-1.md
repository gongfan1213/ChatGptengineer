# 第2章 相似匹配——万物皆可Embedding

第1章简单介绍了Embedding的概念，我们知道了Embedding可以用来表示一个词或一句话。读者可能会有困惑：这和ChatGPT或大语言模型有什么关系？为什么需要Embedding？在哪里需要Embedding？这三个问题可以简单用一句话来概括回答：因为需要获取“相关”上下文。具体来说，NLP领域的不少任务以及大语言模型的应用都需要一定的上下文知识，而Embedding表示技术就是用来获取这些上下文的。这一过程在NLP领域中也被叫作相似匹配——把相关内容转成Embedding表示，然后通过Embedding相似度来获取最相关内容作为上下文。

在本章中，我们将首先进一步了解相似匹配的基础知识，尤其是如何更好地表示一段自然语言文本，以及如何衡量Embedding的相似程度。接下来，我们将介绍ChatGPT相关接口的用法，其他类似接口的用法也差不多。最后，我们将介绍与Embedding相关的几个任务和应用，这里面有些可以用大语言模型解决，但也可以不用大语言模型解决。无论是ChatGPT还是其他大语言模型，它们都只是我们工具箱中的工具，我们将侧重任务和应用，重点介绍如何解决此类问题。我们期望读者能在阅读的过程中感受到目的和方法的区别，方法无论如何，总归是为目的服务的。

## 2.1 相似匹配基础

### 2.1.1 更好的Embedding表示

#### 1. Embedding表示技术回顾
首先，我们简单回顾一下第1章介绍的Embedding表示技术。对于自然语言，因为输入是一段文本，在中文里就是一个一个字，或一个一个词，业内把这个字或词叫作Token。如果要使用模型，拿到一段文本的第一件事，就是把这段文本Token化。当然，可以按字，也可以按词，或按你想要的其他方式，比如每两个字一组或每两个词一组。我们来看下面这个例子。

• 给定文本：人工智能让世界变得更美好。

• 按字Token化：人工 智能 让 世界 变得 更美 好。

• 按词Token化：人工智能 让 世界 变得 更 美好。

• 按字Bi - Gram Token化：人/工 工/智 智/能 能/让 让/世 世/界 界/变 变/得 得/更 更/美 美/好/。

• 按词Bi - Gram Token化：人工智能/让 让/世界 世界/变得 变得/更 更/美好 美好/。

于是自然地就有了一个新的问题：我们应该怎么选择Token化方式？其实每种不同的方式都有优点和不足，英文一般用子词表示，中文以前常见的是字或词的方式，中文的大语言模型基本都使用字 + 词的方式。如第1章所述，这种方式一方面能够更好地表示语义，另一方面对于没见过的词又可以用字的方式来表示，避免了在遇到不在词表中的词时导致的无法识别和处理的情况。

Token化之后，第二件事就是要怎么表示这些Token，我们知道计算机只能处理数字，所以要想办法把这些Token变成计算机所能识别的数字才行。这里需要一个词表，将每个词映射成词表中对应位置的序号。以上面的句子为例，假设以字为粒度，那么词表就可以用一个文本文件来存储，内容如下。

人 

工 

智 

能 

让 

世 

界 

变 

得 

更 

美 

好 

一行一个字，将每个字作为一个Token，此时，0=我，1=们，……，以此类推，我们假设词表大小为N。这里有一点需要注意，就是词表的顺序无关紧要，不过一旦确定下来，训练好模型后就不能再随便调整了。这里所说的调整包括调整顺序、增加词、删除词、修改词等。如果只是调整顺序或删除词，则不需要重新训练模型，但需要手动将Embedding参数也相应地调整顺序或删除对应行。如果是增改词表，则需要重新训练模型，获取增改部分的Embedding参数。接下来就是将这些序号（Token ID）表示成稠密向量（Embedding表示），背后的主要思想如下。

• 把特征固定在某个维度D，比如256、300、768等，这个不重要，总之不再是词表那么大的数字。

• 利用自然语言文本的上下文关系学习一个由D个浮点数组成的稠密向量。


接下来是Embedding的学习过程。首先，随机初始化一个NumPy数组，就像下面这样。

```python
import numpy as np

rng = np.random.default_rng(42)

# 词表大小N=16，维度D=256
table = rng.uniform(size=(16, 256))
table.shape == (16, 256)
```

假设词表大小为16，维度为256，初始化后，我们就得到了一个16×256大小的二维数组，其中的每一行浮点数就表示对应位置的Token。接下来就是通过一定的算法和策略来调整（训练）里面的数字（更新参数）。当训练结束时，最终得到的数组就是词表的Embedding表示，也就是词向量。这种表示方法在深度学习早期（2014年左右）比较流行，不过由于这个矩阵在训练好后就固定不变了，因此它在有些时候就不合适了。比如，“我喜欢苹果”这句话在不同的情况下可能是完全不同的意思，因为“苹果”既可以指水果，也可以指苹果手机。


我们知道，句子才是语义的最小单位，相比Token，我们其实更加关注和需要句子的表示。而且，如果我们能够很好地表示句子，则由于词也可以被看作一个很短的句子，表示起来自然也不在话下。我们还期望可以根据不同上下文动态地获得句子的表示。这中间经历了比较多的探索，但最终走向了在模型架构上做设计——输入任意一段文本，模型经过一定计算后，就可以直接获得对应的向量表示。

#### 2. 如何更好地表示
前面我们都将模型当作黑盒，默认输入一段文本就会给出一个表示。但这中间其实也有不少细节，具体来说，就是如何给出这个表示。下面我们介绍几种常见的方法，并探讨其中的机理。

直观地看，我们可以借鉴词向量的思想，把这里的“词”换成“句”，模型训练完之后，就可以得到句子向量了。不过，稍微思考一下就会发现，其实这在本质上只是粒度更大的一种Token化方式，粒度太大时，有的问题就会更加突出。而且，这样得到的句子向量还有一个问题——无法通过句子向量获取其中的词向量，而在有些场景下又需要词向量。看来，此路难行。

还有一种操作起来更简单的方式，我们在第1章中也提到过，就是直接对词向量取平均。无论一句话或一篇文档有多少个词，找到每个词的词向量，平均就好了，得到的向量大小和词向量一样。事实上，在深度学习NLP刚开始的几年，这种方式一直是主流，也出现了不少关于如何平均的方法，比如使用加权求和，权重可以根据词性、句法结构等设定为一个固定值。

2014年，也就是谷歌公司发布Word2Vec后一年，差不多是同一批人提出了一种表示文档的方法——Doc2Vec，其思想是在每句话的前面增加一个额外的段落Token作为段落的向量表示，我们可以将它视为段落的主题。训练模型可以采用和词向量类似的方式，但每次更新新词向量参数时，需要额外更新这个段落Token向量。直观地看，就是把文档的语义都融入这个特殊的Token向量。不过这种方法存在一个很严重的问题，那就是推理时，如果遇到训练数据集中没有的文档，就需要将这个文档的参数更新到模型里。这不仅不方便，而且效率也低。

之后，随着深度学习进一步发展，涌现出一批模型，其中最为经典的就是TextCNN和RNN。RNN在第1章有过介绍，TextCNN的想法来自图像领域的卷积神经网络（convolutional neural network，CNN）。TextCNN以若干大小固定的窗口在文本上滑动，每个窗口从头到尾滑过，就会得到一组浮点数特征，使用若干不同大小的窗口（一般取2、3、4），就会得到若干不同的特征，将它们拼接起来就可以表示这段文本了。TextCNN的表示能力其实不错，一直以来都作为基准模型使用，很多线上模型也用它。TextCNN的主要问题是只利用了文本的局部特征，没有考虑全局语义。RNN和它的几个变体都是时序模型，从前到后一个Token接一个Token处理。RNN也有不错的表示能力，但它有两个比较明显的不足：一是比较慢，没法并行；二是当文本太长时效果不好。总的来说，这一时期词向量用得比较少，文本的表示主要通过模型架构来体现，Token化的方式以词为主。

2017年，Transformer 横空出世，带来了迄今为止最强的特征表示方式——
自注意力机制。模型开始慢慢变大，从原来的十万、百万级别逐渐增加到亿级
别。文档表示方法并没有太多创新，但由于模型变大，表示效果有了明显提升。
自此，NLP 进入预训练时代——基于 Transformer 训练一个模型，在做任务时都
以该模型为起点，在对应数据上进行微调训练。具有代表性的成果是 BERT 和
GPT，前者用了 Transformer 的编码器，后者用了 Transformer 的解码器。BERT
在每个文档的前面添加了一个 [CLS]Token 来表示整句话的语义，但与 Doc2Vec
不同的是，模型在推理时不需要额外训练，而是根据当前输入，通过计算自动获
得表示。也就是说，同样的输入，相比 Doc2Vec，BERT 因为其强大的表示能力，
可以通过模型计算，不额外训练就能获得不错的文本表示。GPT 在第 1 章有相关
介绍，这里不赘述。无论是哪个预训练模型，底层其实都是对每个 Token 进行计
算（在计算时一般会用到其他的 Token 信息）。所以，预训练模型一般可以获得每
个 Token 位置的向量表示。于是，文档表示依然可以使用那种最常见的方式——
取平均。当然，由于模型架构变得复杂，取平均的方式也变得更加灵活多样，比
如用自注意力作为权重加权平均。

#### 3. 进一步思考
ChatGPT 的出现其实是语言模型的突破，并没有涉及 Embedding，但是由于
模型在处理超长文本上的限制（主要是资源限制和超长距离的上下文依赖问题），
Embedding 成了一个重要组件。我们先不讨论大语言模型，依然把关注点放在
Embedding 上。

接下来主要是笔者的一些思考，期望能与读者共同探讨。如前所述，如今Embedding 已经转变成了模型架构的副产物，架构变强→Token 表示变强→文档
表示变强。第一步目前没什么问题，Token 表示通过架构充分利用了各种信息，
表示效果。第二步目前有点单调，要么是 [CLS]Token，要么
而且可以得到不同层级的抽象。但第二步有点单调，要么是 [CLS]Token，要么
是取平均。这些方法在句子上可能问题不大，因为句子一般比较短，但直接
段落、篇章，甚至更长文本上就不一定了。


还是以人类阅读进行类比（很多模型都是从人类获得启发，比如CNN、自注意力等）。我们在看一句话时，会重点关注其中一些关键词，整体语义可能通过这些关键词就能表达一二。我们在看一段话时，可能依然重点关注的是关键词、包含关键词的关键句等。但是，当我们看一篇文章时，其中的关键词和关键句可能就不那么突出了，我们可能会更加关注这篇文章整体在表达什么，描述这样的表达可能并不会用到文本中的词或句。

也就是说，我们人类处理句子和篇章的方式是不一样的。但是现在，模型把它们当成同样的东西进行处理，而没有考虑中间量变引起的质变。通俗点说，这是几粒沙子和沙堆的区别。我们的模型设计是否可以考虑这样的不同？

最后我们简单总结一下，Embedding在本质上就是一组稠密向量（不用过度关注它是怎么来的），用来表示一段文本（可以是字、词、句、段等）。获取到这个表示后，我们就可以进一步做一些任务。读者不妨先思考一下，当给定任意句子并得到它的固定长度的语义表示时，可以干什么。

### 2.1.2 如何度量Embedding相似度
提起相似度，读者可能首先会想到编辑距离相似度，它可以用来衡量字面量的相似度，也就是文本本身的相似度。但如果是语义层面，我们一般会使用余弦（cosine）相似度，它可以评估两个向量在语义空间中的分布情况，如式（2.1）所示。 

![image](https://github.com/user-attachments/assets/75ac7990-f7db-4c09-ad9d-786877ca0c22)


我们举个例子：
```python
import numpy as np

a = [0.1, 0.2, 0.3]
b = [0.2, 0.3, 0.4]
cosine_ab = (0.1*0.2+0.2*0.3+0.3*0.4)/(np.sqrt(0.1**2+0.2**2+0.3**2) *
                                        np.sqrt(0.2**2+0.3**2+0.4**2))
cosine_ab == 0.9925833339709301
```
在这个例子中，我们首先给定两个向量a和b，然后用式（2.1）计算相似度，得到它们的相似度约为0.9926。

在2.1.1节中，我们得到了一段文本的向量表示；在这里，我们可以计算两个向量的相似度。这意味着我们现在可以知道两段给定文本的相似度，或者说，给定一段文本，我们可以从库里找到与它语义最为相似的若干段文本。这个逻辑会用在很多NLP应用上，我们一般把这个过程叫作文义匹配。不过在正式介绍任务和应用之前，我们先来了解一下ChatGPT相关接口的用法。

### 2.2 ChatGPT接口使用
本节主要介绍两个接口，一个是ChatGPT提供的Embedding接口，另一个是ChatGPT接口。前者可以获取给定文本的向量表示，后者可以直接完成语义匹配任务。

#### 2.2.1 Embedding接口
首先做一些准备工作，主要是设置OPENAI_API_KEY，这里建议读者用环境变量来获取，而不要将自己的密钥明文写在任何代码文件里。当然，更不要上传到开源代码仓库。
```python
import os
import openai
```
```python
# 用环境变量来获取
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
# 或直接填入自己专属的API key（接口密钥），不建议在正式场景下使用
OPENAI_API_KEY = "填入专属的API key"

openai.api_key = OPENAI_API_KEY
```
接下来输入文本，指定相应模型，获取文本对应的Embedding。
```python
text = "我喜欢你"
model = "text-embedding-ada-002"
emb_req = openai.Embedding.create(input=[text], model=model)
```
接口会返回所输入文本的向量表示，结果如下。
```python
emb = emb_req.data[0].embedding
len(emb) == 1536
type(emb) == list
```
可以看到，Embedding表示是一个列表，里面包含1536个浮点数。

OpenAI官方还提供了一个集成接口，既包括获取Embedding，也包括计算相似度，使用起来更加简单（读者也可以尝试自己写一个），如下所示。
```python
from openai.embeddings_utils import get_embedding, cosine_similarity

text1 = "我喜欢你"
text2 = "我中意你"
text3 = "我不喜欢你"
# 注意默认的模型是text-similarity-davinci-001，我们也可以换成text-embedding-ada-002
emb1 = get_embedding(text1)
emb2 = get_embedding(text2)
emb3 = get_embedding(text3)
```
接口直接返回向量表示，结果如下。 

```python
len(emb1) == 12288
type(emb1) == list
```
可以发现，Embedding的长度变了，从1536变成了12288。这主要是因为get_embedding接口默认的模型和前面我们指定的模型不一样。当模型不同时，Embedding的长度（维度）也可能不同。一般情况下，Embedding维度越大，表示效果越佳，但同时计算速度越慢（从调用接口的角度可能感知不明显）。当然，它们的价格也可能不一样。

让我们来计算一下几个文本的相似度，直观感受一下。
```python
cosine_similarity(emb1, emb2) == 0.9246855139297101
cosine_similarity(emb1, emb3) == 0.8578009661644189
cosine_similarity(emb2, emb3) == 0.8205299527695261
```
前两句是一个意思，相似度高一些。第一句和第三句以及第二句和第三句的意思是相反的，所以相似度低一些。我们再换维度为1536的模型试一下效果，如下所示。
```python
text1 = "我喜欢你"
text2 = "我中意你"
text3 = "我不喜欢你"
emb1 = get_embedding(text1, "text-embedding-ada-002")
emb2 = get_embedding(text2, "text-embedding-ada-002")
emb3 = get_embedding(text3, "text-embedding-ada-002")
```
使用方法类似，只是将第二个参数改成了维度为1536的模型，结果如下。
```python
cosine_similarity(emb1, emb2) == 0.8931105629213952
cosine_similarity(emb1, emb3) == 0.9262074073566393
cosine_similarity(emb2, emb3) == 0.845821877417193
```
这个结果不太令人满意。不过，我们正好可以用来探讨关于相似度的一个有意思的观点。为什么很多语义匹配模型认为“我喜欢你”和“我不喜欢你”的相似度比较高？其实，从客观角度来看，这两句话是相似的，它们的结构一样，都 

### 40 | ChatGPT原理与应用开发
在表达一种情感倾向，句式结构也相同，之所以我们觉得它们不相似，只是因为我们只关注了一个（我们想要的）角度 ①。所以，如果想要模型的输出和我们想要的一致，就需要重新设计和训练模型。我们需要明确地告诉模型，“我喜欢你”与“我中意你”比“我喜欢你”与“我不喜欢你”更相似。

因此，在实际使用时，我们最好能够在自己的数据集上进行测试，明确各项指标的表现。如果不满足需求，则考虑是否需要在自己的数据集上专门训练一个Embedding模型。同时，应综合考虑性能、价格等因素。

#### 2.2.2 ChatGPT + 提示词
接下来，我们用万能的ChatGPT尝试一下，注意它不会返回Embedding，而是尝试直接告诉我们答案，如下所示。
```python
content = "请告诉我下面三句话的相似度：\n1. 我喜欢你。\n2. 我中意你。\n3. 我不喜欢你。\n"
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": content}]
)
response.get("choices")[0].get("message").get("content")
```
在这里，我们直接调用了GPT-3.5（也就是ChatGPT）的接口，返回结果如下所示。
1和2相似，都表达了对某人的好感或喜欢之情。而3则与前两句截然相反，表示对某人的反感或不喜欢。

效果看起来不错，不过格式不太好，我们调整一下，进行格式化输出，如下所示。
```python
content += "第一句话用a表示，第二句话用b表示，第三句话用c表示，请以JSON格式输出两两相似度，类似下面这样：\n{\"ab\": a和b的相似度}"
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": content}]
)
response.get("choices")[0].get("message").get("content")
```
注意，这里我们直接在原content基础上增加格式要求，结果如下所示。
{"ab": 0.8, "ac": -1, "bc": 0.7}\n\n解释：a和b的相似度为0.8，因为两句话表达了相同的情感；a和c的相似度为-1，因为两句话表达了相反的情感；b和c的相似度为0.7，因为两句话都是表达情感，但一个是积极情感，一个是消极情感，相似度略低。

可以看到，ChatGPT输出了我们想要的格式，但b和c的结果并不是我们想要的。我们来看看ChatGPT给出的解释：“两句话都是表达情感，但一个是积极情感，一个是消极情感，相似度略低。”这一点和我们之前讨论的关于相似度的观点是类似的。不过，类似ChatGPT这样的大语言模型接口，要在自己的数据上进行训练就不那么方便了。此时，我们可以在提示词中先给出一些类似的示例，让ChatGPT知道我们想要的是语义上的相似。读者不妨自己尝试一下。

### 2.3 相关任务与应用
有的读者可能会疑惑，既然ChatGPT已经这么强大了，为什么还要介绍Embedding这种看起来好像有点“低级”的技术呢？原因我们在本章开头就简单说过了，这里稍微再扩充一下，其实目前来看主要有两点原因：第一，有些问题使用Embedding（或其他非ChatGPT的方式）解决会更加合理，通俗地说就是“杀鸡焉用牛刀”；第二，ChatGPT在性能方面不是特别高效，毕竟是一个Token一个Token“吐”出来的。

关于第一点，我们要额外多说几句。选择技术方案就跟找工作一样，合适最重要。只要你的问题（需求）没变，能解决问题的技术就是好技术。比如，对于 ①可参见苏剑林的文章《用开源的人工标注数据来增强RoFormer-Sim》。 





