（从某种意义上说，它们确实没有那么酷）。然而，这只是一个起点，最新的研究已经将应用范围扩展到了更高难度的问题，如高中、大学乃至国际数学奥林匹克竞赛级别的问题。

### 1. 思维链提示激活推理能力
Wei等人（2022年）首次提出了利用思维链（CoT）激活大语言模型的推理能力。思维链是什么样子的呢？参考图5-1，这里对思维链提示和标准提示做了对比。和传统的标准提示相比，思维链提示需要在样例的回答中加入一个逐步思维的过程。

![image](https://github.com/user-attachments/assets/799798e6-251c-4f7a-ad9a-e4374ed26b2b)


**标准提示**
- **输入**：
  - 问：Roger有5个网球。他买了2罐网球。每罐有3个网球。他现在有多少个网球？
  - 答：答案是11个。
  - 问：食堂有23个苹果。如果他们用了20个来做午餐，并买了6个，他们现在有多少个苹果？
- **模型输出**：
  - 答：答案是27个。（×）

**思维链提示**
- **输入**：
  - 问：Roger有5个网球。他买了2罐网球。每罐有3个网球。他现在有多少个网球？
  - 答：Roger起初有5个网球。2罐，每罐3个网球，总共是6个网球。5 + 6 = 11。答案是11个网球。
  - 问：食堂有23个苹果。如果他们用了20个来做午餐，并买了6个，他们现在有多少个苹果？
- **模型输出**：
  - 答：食堂起初有23个苹果。他们用了20个来做午餐。所以剩下23 - 20 = 3个苹果。他们又买了6个苹果，所以他们现在有3 + 6 = 9个苹果。答案是9个。（√）

**图5-1 思维链提示和标准提示的对照图（Wei等人，2022年）**

此外，他们还发现当使用思维链提示时，随着模型规模增大，出现了如图5-2所示的相变现象。这进一步导致后面大模型涌现能力的发现。思维链提示是展示模型规模扩大后出现涌现能力的典型案例，从图5-2中可以看到，当模型规模较小时，解决率几乎没有变化；但是当模型规模很大时，解决率提升非常明显。这十分清晰地说明了某些能力可能并不存在于小模型中，而只在大模型中可以获取。

通过下面这个统计奇偶数的例子，读者可以进一步感受思维链的魅力。

**标准提示**
```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "在数字3、56、35、96、40、10、84、923、32、20中，有多少个奇数，多少个偶数？"}
    ],
    temperature=0,
)
print(response["choices"][0]["message"]["content"])
```

![image](https://github.com/user-attachments/assets/3a26a6b6-b645-4400-a097-7b0698a1b25a)



**ChatGPT输出如下**：

奇数有4个：3、35、96、923。

偶数有6个：56、40、10、84、32、20。

正确答案是：3个奇数，7个偶数。这里不知道为什么ChatGPT把96也当成奇数了，可能它觉得96和3相关，其他几个和3相关的数字都是奇数，于是它便把96也列为奇数。

**思维链提示**
```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "在数字38、31、89、224中，有多少个奇数，多少个偶数？"},
        {"role": "assistant", "content": "我们一个一个地数：\n 1. 38是偶数，此时累计：偶数1个，奇数0个；\n 2. 31是奇数，此时累计：偶数1个，奇数1个；\n 3. 89是奇数，此时累计：偶数1个，奇数2个；\n 4. 224是偶数，此时累计：偶数2个，奇数2个；\n 所以，一共有2个偶数，2个奇数。"},
        {"role": "user", "content": "在数字3、56、35、96、40、10、84、923、32、20中，有多少个奇数，多少个偶数？"}
    ],
    temperature=0,
)
print(response["choices"][0]["message"]["content"])
```
**ChatGPT输出如下**：
我们一个一个地数：

1. 3是奇数，此时累计：偶数0个，奇数1个；

2. 56是偶数，此时累计：偶数1个，奇数1个；

3. 35是奇数，此时累计：偶数1个，奇数2个；

4
. 96是偶数，此时累计：偶数2个，奇数2个；

5. 40是偶数，此时累计：偶数3个，奇数2个；

6. 10是偶数，此时累计：偶数4个，奇数2个；

7. 84是偶数，此时累计：偶数5个，奇数2个；

8. 923是奇数，此时累计：偶数5个，奇数3个；

9. 32是偶数，此时累计：偶数6个，奇数3个；

10. 20是偶数，此时累计：偶数7个，奇数3个；
所以，一共有7个偶数，3个奇数。


可以看到，在使用思维链提示后，模型对奇偶数统计问题很快就改善了。目前，思维链提示已被证明能改善包括算术、常识判断和符号推理等多种任务的结果。

### 2. 天生的零样本推理器

虽然思维链提示的效果非常好，但构建一条优质的思维链是十分伤脑的，有没有更简单的方法呢？Kojima等人（2022年）进一步发现，大语言模型天生具备零样本推理的能力（即Zero - CoT）①。具体来说，只需要在问题的后面添加类似于“Let's think step by step”（让我们一步步思考）的魔法语句，就能激活模型，让模型进行复杂推理，如图5 - 3所示。有人戏称“这是模型在寻求鼓励”。

**zero - shot思维链提示**

- **输入**：

   - 问：平均而言，Joe每分钟出拳25次。一场比赛持续5轮，每轮3分钟。他一共出拳多少次？

  - 答：Let's think step by step.

- **模型输出**：

在1分钟内，Joe出拳25次。在3分钟内，Joe出拳3×25 = 75次。在这场持续5轮的比赛中，Joe一共出拳5×75 = 375次。（√）

![image](https://github.com/user-attachments/assets/999d97e2-fbec-4d55-b942-edc3bb0b910c)


**图5 - 3 零样本思维链提示示例（Kojima等人，2022年）**

像少样本思维链提示这种精心构造思维链来显式地告知模型进行复杂推理的技术，通常需要耗费不少的人力和物力。相比之下，零样本思维链提示仅仅添加一条魔法语句就能达到非常不错的效果，让模型进行复杂推理，显得十分神奇。

下面让我们通过一个数学问题来熟悉一下零样本思维链提示。

**标准提示**
```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "用一只水桶装水，把水加到原来的2倍，连桶重10千克，如果把水加到原来的5倍，连桶重22千克。桶里原来有水多少千克？"}
    ],
    temperature=0,
)
print(response["choices"][0]["message"]["content"])
```
**ChatGPT输出如下**：

设桶里原来有水x千克，加水后水的重量为2x千克，加水前桶的重量为y千克，则有

2x + y = 10（把水加到原来的2倍，连桶重10千克）

5x + y = 22（把水加到原来的5倍，连桶重22千克）

化简得

x = 6①

因此，桶里原来有水6千克。

这个答案不对，应该是4千克。我们再来看看零样本思维链提示，如下所示。

**零样本思维链提示**

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "user", "content": "用一只水桶装水，把水加到原来的2倍，连桶重10千克，如果把水加到原来的5倍，连桶重22千克。桶里原来有水多少千克？Let's think step by step."}
    ],
    temperature=0,
)
print(response["choices"][0]["message"]["content"])
```

**ChatGPT输出如下**：

设桶里原来有水x千克，桶本身重y千克，则有

第一步：把水加到原来的2倍

桶里的水变成2x千克，连桶重10千克，桶重y = 10 - 2x。

第二步：把水加到原来的5倍
桶
里的水变成5x千克，连桶重22千克，桶重y = 22 - 5x。

由此，我们可以列出一个方程：

10 - 2x = 22 - 5x

化简得

3x = 12

x = 4

所以，桶里原来有水4千克。

通过这个例子我们发现，在给问题加上魔法语句“Let's think step by step”后，ChatGPT的回答明显变长了，而且思路清晰、步骤规范。Zero - CoT论文中提到，与没有加上魔法语句的解答相比，逐步解答的准确率更高，更符合常规逻辑。

使用GPT - 3在MultiArith数学数据集上进行测试，结果显示，在加上“Let's think step by step”这条提示语句后，准确率提高到原来的4倍多，从17.7%上涨到78.7%。此外，也可以尝试其他提示语句，如“Let's think about this logically”（让我们从逻辑上来思考这个问题）、“Let's solve this problem by splitting it into steps”（让我们把这个问题拆分为几步来解决）等，这些提示语句也能提升模型的推理能力。读者可以自行尝试构建属于自己的魔法语句来提高模型的表现。

### 5.2.3 大语言模型复杂推理能力的改善

现在，我们已经知道了通过构建思维链提示或者使用零样本思维链的方式，可以激活大语言模型的复杂推理能力。那么，我们还可以继续提升模型的复杂推理能力吗？答案是肯定的，下面我们就来看看进一步改善大语言模型复杂推理能力的方法。

### 1. 复杂问题分解，逐个击破

如前所述，我们经常使用一种思维技巧，即分析和综合，通过将问题分解成更小的部分，并对每一部分进行分析，最终综合各个部分的结果得出整体结论。那么，这种思维技巧是否可以应用于大语言模型的复杂推理呢？答案是肯定的。Zhou等人（2022年）基于这种思维技巧，提出了最少到最多（least - to - most）提示技术，如图5 - 4所示①。最少到最多提示将推理过程分解为两个步骤：首先将问题分解为更简单的子问题，然后逐步解决这些更简单的子问题。

![image](https://github.com/user-attachments/assets/8f1d45ac-1615-42cc-b715-dd3910b8ad3b)



**图5 - 4 最少到最多提示示例（Zhou等人，2022年）**

- **问题**：问：如果停车场里有3辆车，然后又有两辆车到达，停车场里一共有多少辆车？

- **问题分解**：

  - 问：第一辆车到达后停车场里有多少辆车？

  - 问：第二辆车到达后停车场里有多少辆车？

- **子问题求解**：

  - 问：第一辆车到达后停车场里有多少辆车？

  - 答：最初有3辆车。第一辆车到达后，停车场里有3 + 1 = 4辆车。

  - 问：第二辆车到达后停车场里有多少辆车？

  - 答：第一辆车到达后，停车场里有3 + 1 = 4辆车。第二辆车到达后，停车场里有4 + 1 = 5辆车。

利用最少到最多提示技术，就可以有效地提升大语言模型的复杂推理能力。它能使大语言模型在处理过程中逐步增加对问题的理解和认识，避免受到过多信息和复杂性的困扰。这种分解和逐步解决的方式使整个推理过程更加可控和可管理，有助于提高推理的准确性和效率。类似地，Khot等人（2022年）提出了分解提示（decomposed prompting）技术，这种技术通过将复杂任务分解为更简单的子任务，然后逐一解决这些子任务，来提升大语言模型处理复杂任务的

① Zhou D, Schärli N, Hou L, et al. Least - to - Most Prompting Enables Complex Reasoning in Large Language Models[J]. 2022. DOI:10.48550/arXiv.2205.10625. 
