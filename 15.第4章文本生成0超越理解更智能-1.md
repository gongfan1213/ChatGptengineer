### 第4章 文本生成——超越理解更智能

在第3章中，我们学习了如何使用大语言模型完成NLU任务，包括文本分类、实体和关系抽取等，这些任务在本质上是分类任务，也就是将文本转换为结构化的表述。在理解文本的基础上，我们常常面临着更复杂的任务——根据已有的文本生成一段新的文本，这类任务被称作NLG任务，它也是NLP领域的一个重要研究方向。

事实上，绝大多数的NLP任务可以描述为NLG任务，甚至描述为文本生成任务，也就是将文本作为输入并将新的文本作为输出。举例来说，文本分类任务可以理解为输出类别名，如猫/狗、是/否；文本纠错任务可以理解为输入有错误的文本并加以理解，然后输出正确的文本描述；智能问答可以理解为根据背景知识及问句进行推理，输出相应的回复。

可以说，文本生成任务的应用相当广，本章将介绍一些常见的文本生成任务，主要包括文本摘要与机器翻译，还包括曾经不属于文本生成任务，但如今也能使用NLG技术来解决的任务——文本纠错。

#### 4.1 文本生成任务基础

文本分类任务的本质是，输入一段文本，并给定可以选择的类别数量，预测文本和每个类别的匹配概率，输出概率最高的类别。最简单的文本生成方式是，输入一段文本，并给定包含N个词的词表，在每个时刻根据当前已有文本，预测下一个词出现的概率，输出出现概率最高的那个词，这便是最早的语言模型。


```python
import numpy as np

# 定义词表和概率
vocab = ["我", "爱", "自然", "语言", "处理"]
word_freq = {"我": 0.1, "爱": 0.2, "自然": 0.3, "语言": 0.2, "处理": 0.2}
word_to_vec = {w: i for i, w in enumerate(vocab)}

next_word_prob = {
    "我": {"爱": 0.4, "自然": 0.3, "语言": 0.1, "处理": 0.2},
    "爱": {"我": 0.3, "自然": 0.3, "语言": 0.2, "处理": 0.2},
    "自然": {"我": 0.2, "爱": 0.2, "语言": 0.4, "处理": 0.2},
    "语言": {"我": 0.1, "爱": 0.1, "自然": 0.3, "处理": 0.5},
    "处理": {"我": 0.3, "爱": 0.2, "自然": 0.3, "处理": 0.2}
}

# 根据词表和概率选择下一个词
def select_next_word(current_word):
    next_word = np.random.choice(
        list(next_word_prob[current_word].keys()),
        p=list(next_word_prob[current_word].values())
    )
    return next_word

# 生成文本序列并输出
text = w = "我"
for i in range(3):
    w = select_next_word(w)
    text += w

text == "我爱自然语言"
```

以上是一个简单的文本生成示例。我们首先给出包含N个词的词表，并给出在给定一个词时出现下一个词的概率，这往往可以通过语料库中的共现关系得到。在推理时，根据词表和概率，随机选择一个词作为输出。

当然，由于文本生成任务通常需要考虑上下文、语法结构等，单纯的基于概率的语言模型没法生成理想的文本，因此有了更多的基于深度学习的优化方法，如编码器 - 解码器模型，BERT、GPT等预训练模型，以及生成对抗网络（generative adversarial network，GAN）等。

在训练阶段，我们常常采用交叉熵损失来衡量生成的文本与真实文本之间的差异；在推理阶段，我们常采用ROUGE（recall - oriented understudy for gisting evaluation，面向召回的排序评估替补）或BLEU（bilingual evaluation understudy，双语评估替补）指标来评价所生成文本的准确性与连贯性。对于评测阶段，后续章节会进行详细介绍。


#### 4.2 文本摘要

##### 4.2.1 什么是文本摘要

文本摘要指的是用精练的文本来概括整篇文章的大意，使得用户能够通过阅读文本摘要来大致了解文章的主要内容。


##### 4.2.2 常见的文本摘要技术

站在实现方法的角度，文本摘要主要包括以下三种。

- 抽取式摘要：从原文档中提取现成的句子作为摘要句。

- 压缩式摘要：对原文档的冗余信息进行过滤，压缩文本作为摘要。 

- 生成式摘要：基于NLG技术，根据原文档内容，由算法模型自己生成自然语言描述。



以下是一个基于mT5模型（T5模型的多语言版本）的文本摘要样例。注意，模型较大，如果下载失败，可前往Hugging Face官方网站搜索“mT5_multilingual_XLSum”模型，使用其提供的Hosted Inference接口进行测试。


```python
import re
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# 载入模型
tokenizer = AutoTokenizer.from_pretrained("csebuetnlp/mT5_multilingual_XLSum")
model = AutoModelForSeq2SeqLM.from_pretrained("csebuetnlp/mT5_multilingual_XLSum")

WHITESPACE_HANDLER = lambda k: re.sub("\s+", " ", re.sub("\n+", " ", k.strip()))

text = """自动信任协商主要解决跨安全域的信任建立问题，使陌生实体通过反复的、双向的访问控制策略和数字证书的相互披露而逐步建立信任关系。由于信任建立的方式独特和应用环境复杂，自动信任协商面临多方面的安全威胁，针对协商的攻击大多超出常规防范措施所保护的范围，因此有必要对自动信任协商中的攻击手段进行专门分析，按攻击特点对自动信任协商中存在的各种攻击方式进行分类，并介绍相应的防御措施，总结当前研究工作的不足，以及对未来的研究进行展望。"""
text = WHITESPACE_HANDLER(text)
input_ids = tokenizer(
    [text], return_tensors="pt", padding="max_length", truncation=True,
    max_length=512)["input_ids"]

# 生成结果文本
output_ids = model.generate(input_ids=input_ids, max_length=84, no_repeat_ngram_size=2, num_beams=4)[0]
output_text = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)

# 摘要文本
output_text == "自动信任协商（AI）是互信关系建立的最新研究工作的一部分。"
```

上面的脚本是mT5模型在多语言上的预训练模型，并基于XLSum文本摘要数据集进行了微调。对于输入的文本，我们先使用tokenizer将句子Token化并转为对应的ID，再使用model.generate输出生成的Token ID列表，最后使用tokenizer解码出对应的摘要文本。

可以看到，虽然我们使用了一个很复杂的模型，并且该模型也在摘要数据上进行了微调，但输出的结果仍然不算完美。模型输出了更简短的文本，但是只总结了原文的第一句，对于后续提到的安全威胁、防御措施等，仅以“最新研究工作”一笔带过。

##### 4.2.3 基于OpenAI接口的文本摘要实验

与前几章类似，我们将调用OpenAI接口，利用大语言模型的内在理解能力，实现文本摘要功能。更进一步地，我们还将尝试使用OpenAI接口完成微调工作。

1. **简单上手版：调用预训练模型**

以下是调用基础版GPT模型完成文本摘要任务的样例。使用openai.Completion.create命令启动接口，并指定模型名称，将任务描述写入提示词。值得注意的是，通过提示词控制字数并不一定准确。


```python
def summarize_text(text):
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=f"请对以下文本进行总结，注意总结的凝练性，将总结字数控制在20个字以内：\n{text}\n",
        temperature=0.3,
        max_tokens=500,
    )

    summarized_text = response.choices[0].text.strip()
    return summarized_text

text = """自动信任协商主要解决跨安全域的信任建立问题，使陌生实体通过反复的、双向的访问控制策略和数字证书的相互披露而逐步建立信任关系。由于信任建立的方式独特和应用环境复杂，自动信任协商面临多方面的安全威胁，针对协商的攻击大多超出常规防范措施所保护的范围，因此有必要对自动信任协商中的攻击手段进行专门分析，按攻击特点对自动信任协商中存在的各种攻击方式进行分类，并介绍相应的防御措施，总结当前研究工作的不足，以及对未来的研究进行展望。"""
output_text = summarize_text(text)

# 摘要文本
output_text == "自动信任协商解决跨安全域信任建立问题，但面临多种安全威胁，需要分析攻击方式及防御措施。"
# 摘要文本的长度
len(output_text) == 43
```

接下来，我们尝试通过调用ChatGPT来实现相同的功能。


```python
def summarize_text(text):
    content = f"请对以下文本进行总结，注意总结的凝练性，将总结字数控制在20个字以内：\n{text}"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": content}],
        temperature=0.3
    )
    summarized_text = response.get("choices")[0].get("message").get("content")
    return summarized_text

text = """自动信任协商主要解决跨安全域的信任建立问题，使陌生实体通过反复的、双向的访问控制策略和数字证书的相互披露而逐步建立信任关系。由于信任建立的方式独特和应用环境复杂，自动信任协商面临多方面的安全威胁，针对协商的攻击大多超出常规防范措施所保护的范围，因此有必要对自动信任协商中的攻击手段进行专门分析，按攻击特点对自动信任协商中存在的各种攻击方式进行分类，并介绍相应的防御措施，总结当前研究工作的不足，以及对未来的研究进行展望。"""
output_text = summarize_text(text)

# 摘要文本
output_text == "自动信任协商解决跨域信任建立，但面临多方面安全威胁，须分类防御。研究不足，未来展望。"
# 摘要文本的长度
len(output_text) == 42
```

总的来说，这两个接口在未经微调的文本摘要任务上，已经表现出比mT5模型更为优秀的效果。对于文本生成任务，每次输入相同的问题，输出的结果可能存在一定的随机性，我们也可以称之为创造性，可由temperature参数控制创造程度，temperature越高，模型输出的自由度越大。对于文本摘要、文本纠错、机器翻译等任务，我们希望输出偏向于标准的答案，因此temperature可以设置得更低一些；而对于续写小说之类的任务，我们希望输出可能是天马行空的，因此temperature可以设置得更高一些。

2. **进阶优化版：基于自定义语料微调模型**

对于垂直领域的数据或任务，有时直接使用大语言模型的效果不佳。当然，由于ChatGPT强大的内在理解能力，在某些情况下使用一个比较好的提示词，通过零样本或少样本也能得到一个不错的结果。下面我们使用中文科学文献（Chinese Scientific Literature，CSL）摘要数据集，以ada模型为例，简单介绍如何通过自定义语料库对模型进行微调。

CSL摘要数据集是计算机领域的论文摘要数据和标题数据，包含3500条数据。其中标题数据的平均字数为18，字数标准差为4，最大字数为41，最小字数为6；论文摘要数据的平均字数为200，字数标准差为63，最大字数为631，最小字数为41。


```python
import json
with open("dataset/csl_data.json", "r", encoding="utf-8") as f:
    data = json.load(f)
```
首先读取数据集，其中一条样例数据如下所示。

```python
data[-1] == {
    "title": "自动信任协商中的攻击与防范",
    "content": "自动信任协商主要解决跨安全域的信任建立问题，使陌生实体通过反复的、双向的访问控制策略和数字证书的相互披露而逐步建立信任关系。由于信任建立的方式独特和应用环境复杂，自动信任协商面临多方面的安全威胁，针对协商的攻击大多超出常规防范措施所保护的范围，因此有必要对自动信任协商中的攻击手段进行专门分析，按攻击特点对自动信任协商中存在的各种攻击方式进行分类，并介绍相应的防御措施，总结当前研究工作的不足，以及对未来的研究进行展望。"
}
```
接下来，我们需要将自定义语料库转换为OpenAI所需要的标准格式。OpenAI提供了一个数据准备工具fine_tunes.prepare_data，我们只需要将数据集整理成它所要求的格式：第一列列名为prompt，表示输入文本；第二列列名为completion，表示输出文本。将数据集保存为JSON格式，一行为一条记录，即可使用该数据准备工具。


```python
import pandas as pd

df = pd.DataFrame(data)
df = df[["content", "title"]]
df.columns = ["prompt", "completion"]
df_train = df.iloc[:500]
df_train.head(5)
```
构造好的训练数据样例如表4 - 1所示。

|索引|prompt|completion|
| ---- | ---- | ---- |
|0|提出了一种新的保细节的变形算法，可以使网格模型进行尽量刚性的变形，以减少变形中几何细节的扭曲……|保细节的网格刚性变形算法|
|1|实时服装动画生成技术能够为三维虚拟角色实时地生成逼真的服装动态效果，在游戏娱乐、虚拟服装设计……|一种基于混合模型的实时虚拟人服装动画方法|
|2|提出了一种基于模糊主分量分析（FPCA）技术的人脸遮挡检测与去除方法。首先，有遮挡人脸被投影到……|人脸遮挡区域检测与重建|
|3|图像匹配技术在计算机视觉、遥感和医学图像分析等领域有着广泛的应用背景。针对传统的相关匹配算法……|一种基于奇异值分解的图像匹配算法|
|4|提出了一种基于片相似性的各向异性扩散图像去噪方法。传统的各向异性图像去噪方法都基于单个像素……|片相似性各向异性扩散图像去噪|

将DataFrame保存成JSONL格式。注意，由于数据集中存在中文，使用常规的ASCII编码可能会出现编译问题。为此，可以设置参数force_ascii=False，如下所示。

```python
df_train.to_json("dataset/csl_summarize_finetune.jsonl", orient="records", lines=True, force_ascii=False)
```
调用fine_tunes.prepare_data工具，在处理数据的过程中，该工具会自动根据数据情况做一些转换，例如将输入输出转换为小写，在prompt后增加 --> 符号，在completion后增加 \n 标识，等等。这些内容在第3章中也有 
